{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv-python\n",
    "import cv2\n",
    "\n",
    "# mediapipe人工智能工具包\n",
    "import mediapipe as mp\n",
    "\n",
    "# 进度条库\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 时间库\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入三维人脸关键点检测模型\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "model = mp_face_mesh.FaceMesh(   \n",
    "        static_image_mode=False,      # 是静态图片还是连续视频帧，摄像头画面为连续视频帧，此处选False\n",
    "        refine_landmarks=True,       # 使用Attention Mesh Model，对嘴唇、眼睛、瞳孔周围的关键点精细定位\n",
    "        max_num_faces=5,              # 最多检测几张脸\n",
    "        min_detection_confidence=0.5, # 置信度阈值\n",
    "        min_tracking_confidence=0.5,  # 追踪阈值\n",
    ")\n",
    "\n",
    "# 导入可视化函数和可视化样式\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "# 关键点可视化样式\n",
    "landmark_drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=2, color=[66,77,229])\n",
    "# 轮廓可视化样式\n",
    "connection_drawing_spec = mp_drawing.DrawingSpec(thickness=2, circle_radius=1, color=[223,155,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理单帧的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# 处理帧函数\n",
    "def process_frame(img):\n",
    "    \n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "    scaler = 1 # 文字大小\n",
    "    \n",
    "    # 获取图像宽高\n",
    "    h,w = img.shape[0], img.shape[1]\n",
    "    # BGR转RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # 将RGB图像输入模型，获取预测结果\n",
    "    results = model.process(img_RGB)\n",
    "\n",
    "    if results.multi_face_landmarks: # 如果检测出人脸\n",
    "        \n",
    "        for face_landmarks in results.multi_face_landmarks: # 遍历每一张脸\n",
    "            mp_drawing.draw_landmarks(\n",
    "                  image=img,\n",
    "                  landmark_list=face_landmarks,\n",
    "                  # connections=mp_face_mesh.FACEMESH_TESSELATION, # 可视化Face Mesh\n",
    "                  connections=mp_face_mesh.FACEMESH_CONTOURS,  # 可视化脸轮廓\n",
    "                  landmark_drawing_spec=landmark_drawing_spec, # 关键点圆圈样式\n",
    "                  connection_drawing_spec=connection_drawing_spec) # 轮廓样式\n",
    "            for idx, coord in enumerate(face_landmarks.landmark): # 遍历每一个关键点\n",
    "                cx = int(coord.x * w)\n",
    "                cy = int(coord.y * h)\n",
    "                # 图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "                img = cv2.putText(img, 'Face Detected', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "                img = cv2.putText(img, str(idx), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.3*scaler, (0, 255, 0), 1)\n",
    "    else:\n",
    "        img = cv2.putText(img, 'No Face Detected', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    \n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)  \n",
    "    \n",
    "    img = cv2.putText(img, 'FPS  '+str(int(FPS)), (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用摄像头获取每帧（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.573] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "# 调用摄像头逐帧实时处理模板\n",
    "# 不需修改任何代码，只需修改process_frame函数即可\n",
    "\n",
    "# 导入opencv-python\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 打开cap\n",
    "cap.open(0)\n",
    "\n",
    "# 无限循环，直到break被触发\n",
    "while cap.isOpened():\n",
    "    # 获取画面\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Error')\n",
    "        break\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## !!!处理帧函数\n",
    "    frame = process_frame(frame)\n",
    "    \n",
    "    # 展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "\n",
    "    if cv2.waitKey(1) in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "        break\n",
    "    \n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 视频逐帧处理（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频逐帧处理代码模板\n",
    "# 不需修改任何代码，只需定义process_frame函数即可\n",
    "\n",
    "def generate_video(input_path='./videos/three-hands.mp4'):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    \n",
    "    print('视频开始处理',input_path)\n",
    "    \n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为',frame_count)\n",
    "    \n",
    "    # cv2.namedWindow('Crack Detection and Measurement Video Processing')\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    \n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count-1) as pbar:\n",
    "        try:\n",
    "            while(cap.isOpened()):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                # 处理帧\n",
    "                # frame_path = './temp_frame.png'\n",
    "                # cv2.imwrite(frame_path, frame)\n",
    "                try:\n",
    "                    frame = process_frame(frame)\n",
    "                except:\n",
    "                    print('error')\n",
    "                    pass\n",
    "                \n",
    "                if success == True:\n",
    "                    # cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    # break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频开始处理 videos/single_person2.mp4\n",
      "视频总帧数为 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频已保存 out-single_person2.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_video(input_path='videos/single_person2.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果遇到Error，需检查其它notebook是否占用了摄像头，需在其它notebook中restart kernel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dg_demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29ded39bd84ccde43438c3db4c0b346c1217eab52822133991d7d581c3429a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
