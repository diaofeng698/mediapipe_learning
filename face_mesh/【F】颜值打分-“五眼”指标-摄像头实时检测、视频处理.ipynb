{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv-python\n",
    "import cv2\n",
    "import numpy as np\n",
    "# mediapipe人工智能工具包\n",
    "import mediapipe as mp\n",
    "# 进度条库\n",
    "from tqdm import tqdm\n",
    "# 时间库\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入三维人脸关键点检测模型\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "model = mp_face_mesh.FaceMesh(   \n",
    "        static_image_mode=False,      # 是静态图片还是连续视频帧，摄像头画面为连续视频帧，此处选False\n",
    "        refine_landmarks=True,       # 使用注意力机制Attention Mesh Model，对嘴唇、眼睛、瞳孔周围的关键点精细定位\n",
    "        max_num_faces=5,              # 最多检测几张脸\n",
    "        min_detection_confidence=0.5, # 置信度阈值\n",
    "        min_tracking_confidence=0.5,  # 追踪阈值\n",
    ")\n",
    "\n",
    "# 导入可视化绘图函数\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1, color=[66,77,229])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理单帧的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理帧函数\n",
    "def process_frame(img):\n",
    "    \n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 获取图像宽高\n",
    "    h,w = img.shape[0], img.shape[1]\n",
    "    # BGR转RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # 将RGB图像输入模型，获取预测结果\n",
    "    results = model.process(img_RGB)\n",
    "\n",
    "    # 文字大小\n",
    "    scaler = 1\n",
    "\n",
    "    if results.multi_face_landmarks: # 如果检测出人脸\n",
    "\n",
    "        # 获取相关关键点坐标\n",
    "        # 脸轮廓最左点\n",
    "        FL = results.multi_face_landmarks[0].landmark[234]; FL_X, FL_Y = int(FL.x * w), int(FL.y * h); FL_Color = (0,0,255)\n",
    "        img = cv2.circle(img,(FL_X, FL_Y), 5, FL_Color, -1)\n",
    "        # 脸上边缘\n",
    "        FT = results.multi_face_landmarks[0].landmark[10]; FT_X, FT_Y = int(FT.x * w), int(FT.y * h); FT_Color = (31,41,81)\n",
    "        # img = cv2.circle(img,(FT_X, FT_Y), 5, FT_Color, -1)\n",
    "        # 脸下边缘\n",
    "        FB = results.multi_face_landmarks[0].landmark[152]; FB_X, FB_Y = int(FB.x * w), int(FB.y * h); FB_Color = (31,41,81)\n",
    "        # img = cv2.circle(img,(FB_X, FB_Y), 5, FB_Color, -1)\n",
    "        # 脸轮廓最右点\n",
    "        FR = results.multi_face_landmarks[0].landmark[454]; FR_X, FR_Y = int(FR.x * w), int(FR.y * h); FR_Color = (0,255,0)\n",
    "        img = cv2.circle(img,(FR_X, FR_Y), 5, FR_Color, -1)\n",
    "        # 左边眼睛左眼角\n",
    "        ELL = results.multi_face_landmarks[0].landmark[33]; ELL_X, ELL_Y = int(ELL.x * w), int(ELL.y * h); ELL_Color = (255,0,0)\n",
    "        img = cv2.circle(img,(ELL_X, ELL_Y), 5, ELL_Color, -1)\n",
    "        # 左边眼睛右眼角\n",
    "        ELR = results.multi_face_landmarks[0].landmark[133]; ELR_X, ELR_Y = int(ELR.x * w), int(ELR.y * h); ELR_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(ELR_X, ELR_Y), 5, ELR_Color, -1)\n",
    "        # 右边眼睛左眼角\n",
    "        ERL = results.multi_face_landmarks[0].landmark[362]; ERL_X, ERL_Y = int(ERL.x * w), int(ERL.y * h); ERL_Color = (223,155,6)\n",
    "        img = cv2.circle(img,(ERL_X, ERL_Y), 5, ERL_Color, -1)\n",
    "        # 右边眼睛右眼角\n",
    "        ERR = results.multi_face_landmarks[0].landmark[263]; ERR_X, ERR_Y = int(ERR.x * w), int(ERR.y * h); ERR_Color = (151,57,224)\n",
    "        img = cv2.circle(img,(ERR_X, ERR_Y), 5, ERR_Color, -1)\n",
    "\n",
    "        # 计算“五眼指标”\n",
    "        # 从左往右六个点的横坐标\n",
    "        Six_X = np.array([FL_X, ELL_X, ELR_X, ERL_X, ERR_X, FR_X])\n",
    "        # 从最左到最右的距离\n",
    "        Left_Right = FR_X - FL_X\n",
    "        # 从左往右六个点间隔的五个距离，并归一化\n",
    "        Five_Distance = 100 * np.diff(Six_X) / Left_Right\n",
    "        # 两眼宽度的平均值\n",
    "        Eye_Width_Mean = np.mean([Five_Distance[1], Five_Distance[3]])\n",
    "        # 五个距离 与 两眼宽度均值 的差\n",
    "        Five_Eye_Diff = Five_Distance - Eye_Width_Mean\n",
    "        # 求L2范数，作为颜值的“五眼”评价指标\n",
    "        Five_Eye_Metrics = np.linalg.norm(Five_Eye_Diff)\n",
    "        # 画直线\n",
    "        cv2.line(img,(FL_X, FT_Y),(FL_X, FB_Y), FL_Color, 2)\n",
    "        cv2.line(img,(ELL_X, FT_Y),(ELL_X, FB_Y), ELL_Color, 2)\n",
    "        cv2.line(img,(ELR_X, FT_Y),(ELR_X, FB_Y), ELR_Color, 2)\n",
    "        cv2.line(img,(ERL_X, FT_Y),(ERL_X, FB_Y), ERL_Color, 2)\n",
    "        cv2.line(img,(ERR_X, FT_Y),(ERR_X, FB_Y), ERR_Color, 2)\n",
    "        cv2.line(img,(FR_X, FT_Y),(FR_X, FB_Y), FR_Color, 2)\n",
    "        cv2.line(img,(FL_X, FT_Y),(FR_X, FT_Y), FT_Color, 2)\n",
    "        cv2.line(img,(FL_X, FB_Y),(FR_X, FB_Y), FB_Color, 2)\n",
    "\n",
    "        scaler = 1\n",
    "        img = cv2.putText(img, 'Five Eye Metrics {:.2f}'.format(Five_Eye_Metrics), (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'Distance 1 {:.2f}'.format(Five_Eye_Diff[0]), (25 * scaler, 150 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'Distance 2 {:.2f}'.format(Five_Eye_Diff[2]), (25 * scaler, 200 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'Distance 3 {:.2f}'.format(Five_Eye_Diff[4]), (25 * scaler, 250 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "\n",
    "    else:\n",
    "        img = cv2.putText(img, 'No Face Detected', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    \n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)\n",
    "    img = cv2.putText(img, 'FPS  '+str(int(FPS)), (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用摄像头获取每帧（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用摄像头逐帧实时处理模板\n",
    "# 不需修改任何代码，只需修改process_frame函数即可\n",
    "\n",
    "# 导入opencv-python\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 打开cap\n",
    "cap.open(0)\n",
    "\n",
    "# 无限循环，直到break被触发\n",
    "while cap.isOpened():\n",
    "    # 获取画面\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Error')\n",
    "        break\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## !!!处理帧函数\n",
    "    frame = process_frame(frame)\n",
    "    \n",
    "    # 展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "\n",
    "    if cv2.waitKey(1) in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "        break\n",
    "    \n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果遇到Error，需检查其它notebook是否占用了摄像头，需在其它notebook中restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 视频逐帧处理（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频逐帧处理代码模板\n",
    "# 不需修改任何代码，只需定义process_frame函数即可\n",
    "\n",
    "def generate_video(input_path='./videos/three-hands.mp4'):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    \n",
    "    print('视频开始处理',input_path)\n",
    "    \n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为',frame_count)\n",
    "    \n",
    "    # cv2.namedWindow('Crack Detection and Measurement Video Processing')\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    \n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count-1) as pbar:\n",
    "        try:\n",
    "            while(cap.isOpened()):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                # 处理帧\n",
    "                # frame_path = './temp_frame.png'\n",
    "                # cv2.imwrite(frame_path, frame)\n",
    "                try:\n",
    "                    frame = process_frame(frame)\n",
    "                except:\n",
    "                    print('error')\n",
    "                    pass\n",
    "                \n",
    "                if success == True:\n",
    "                    # cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    # break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_video(input_path='videos/single_person.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
