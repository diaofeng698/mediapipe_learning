{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv-python\n",
    "import cv2\n",
    "import numpy as np\n",
    "# mediapipe人工智能工具包\n",
    "import mediapipe as mp\n",
    "# 进度条库\n",
    "from tqdm import tqdm\n",
    "# 时间库\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入三维人脸关键点检测模型\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "model = mp_face_mesh.FaceMesh(   \n",
    "        static_image_mode=False,      # 是静态图片还是连续视频帧，摄像头画面为连续视频帧，此处选False\n",
    "        refine_landmarks=True,       # 使用注意力机制Attention Mesh Model，对嘴唇、眼睛、瞳孔周围的关键点精细定位\n",
    "        max_num_faces=5,              # 最多检测几张脸\n",
    "        min_detection_confidence=0.5, # 置信度阈值\n",
    "        min_tracking_confidence=0.5,  # 追踪阈值\n",
    ")\n",
    "\n",
    "# 导入可视化绘图函数\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1, color=[66,77,229])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 处理单帧的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# 处理帧函数\n",
    "def process_frame(img):\n",
    "    \n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "\n",
    "    # 获取图像宽高\n",
    "    h,w = img.shape[0], img.shape[1]\n",
    "    # BGR转RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # 将RGB图像输入模型，获取预测结果\n",
    "    results = model.process(img_RGB)\n",
    "\n",
    "    # 可视化参数\n",
    "    scaler = 1 # 字体大小\n",
    "    radius = 5 # 关键点圆的半径\n",
    "    lw = 2 # 直线线宽\n",
    "\n",
    "    if results.multi_face_landmarks: # 如果检测出人脸\n",
    "        \n",
    "        # 可视化468个关键点及对应的编号\n",
    "        for face_landmarks in results.multi_face_landmarks: # 遍历每一张脸\n",
    "            mp_drawing.draw_landmarks(\n",
    "                  image=img,\n",
    "                  landmark_list=face_landmarks,\n",
    "                  connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                  landmark_drawing_spec=drawing_spec,\n",
    "                  connection_drawing_spec=drawing_spec)\n",
    "            for idx, coord in enumerate(face_landmarks.landmark): # 遍历每一个关键点\n",
    "                cx = int(coord.x * w)\n",
    "                cy = int(coord.y * h)\n",
    "                # 图片，添加的文字，左上角坐标，字体，字体大小，颜色，字体粗细\n",
    "                img = cv2.putText(img, str(idx), (cx, cy), cv2.FONT_HERSHEY_SIMPLEX, 0.2*scaler, (0, 255, 0), 1)\n",
    "\n",
    "        # 获取相关关键点坐标\n",
    "        \n",
    "        # 脸轮廓四周边缘点\n",
    "        # 脸上边缘\n",
    "        FT = results.multi_face_landmarks[0].landmark[10]; FT_X, FT_Y = int(FT.x * w), int(FT.y * h); FT_Color = (31,41,81)\n",
    "        # img = cv2.circle(img,(FT_X, FT_Y), radius, FT_Color, -1)\n",
    "        # 脸轮廓最左点\n",
    "        FL = results.multi_face_landmarks[0].landmark[234]; FL_X, FL_Y = int(FL.x * w), int(FL.y * h); FL_Color = (0,0,255)\n",
    "        # img = cv2.circle(img,(FL_X, FL_Y), radius, FL_Color, -1)\n",
    "        # 脸轮廓最下边缘\n",
    "        FB = results.multi_face_landmarks[0].landmark[152]; FB_X, FB_Y = int(FB.x * w), int(FB.y * h); FB_Color = (31,41,81)\n",
    "        # img = cv2.circle(img,(FB_X, FB_Y), radius, FB_Color, -1)\n",
    "        # 脸轮廓最右点\n",
    "        FR = results.multi_face_landmarks[0].landmark[454]; FR_X, FR_Y = int(FR.x * w), int(FR.y * h); FR_Color = (0,255,0)\n",
    "        # img = cv2.circle(img,(FR_X, FR_Y), radius, FR_Color, -1)\n",
    "         \n",
    "        # 五眼\n",
    "        # 左边眼睛左眼角\n",
    "        ELL = results.multi_face_landmarks[0].landmark[33]; ELL_X, ELL_Y = int(ELL.x * w), int(ELL.y * h); ELL_Color = (255,0,0)\n",
    "        img = cv2.circle(img,(ELL_X, ELL_Y), radius, ELL_Color, -1)\n",
    "        # 左边眼睛右眼角\n",
    "        ELR = results.multi_face_landmarks[0].landmark[133]; ELR_X, ELR_Y = int(ELR.x * w), int(ELR.y * h); ELR_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(ELR_X, ELR_Y), radius, ELR_Color, -1)\n",
    "        # 右边眼睛左眼角\n",
    "        ERL = results.multi_face_landmarks[0].landmark[362]; ERL_X, ERL_Y = int(ERL.x * w), int(ERL.y * h); ERL_Color = (223,155,6)\n",
    "        img = cv2.circle(img,(ERL_X, ERL_Y), radius, ERL_Color, -1)\n",
    "        # 右边眼睛右眼角\n",
    "        ERR = results.multi_face_landmarks[0].landmark[263]; ERR_X, ERR_Y = int(ERR.x * w), int(ERR.y * h); ERR_Color = (151,57,224)\n",
    "        img = cv2.circle(img,(ERR_X, ERR_Y), radius, ERR_Color, -1)\n",
    "        # 计算“五眼指标”\n",
    "        # 从左往右六个点的横坐标\n",
    "        Six_X = np.array([FL_X, ELL_X, ELR_X, ERL_X, ERR_X, FR_X])\n",
    "        # 从最左到最右的距离\n",
    "        Left_Right = FR_X - FL_X\n",
    "        # 从左往右六个点间隔的五个距离，并归一化\n",
    "        Five_Distance = 100 * np.diff(Six_X) / Left_Right\n",
    "        # 两眼宽度的平均值\n",
    "        Eye_Width_Mean = np.mean([Five_Distance[1], Five_Distance[3]])\n",
    "        # 五个距离 与 两眼宽度均值 的差\n",
    "        Five_Eye_Diff = Five_Distance - Eye_Width_Mean\n",
    "        # 求L2范数，作为颜值的“五眼”评价指标\n",
    "        Five_Eye_Metrics = np.linalg.norm(Five_Eye_Diff)\n",
    "        \n",
    "        # 三庭\n",
    "        # 眉心\n",
    "        MX = results.multi_face_landmarks[0].landmark[9]; MX_X, MX_Y = int(MX.x * w), int(MX.y * h); MX_Color = (29,123,243)\n",
    "        img = cv2.circle(img,(MX_X, MX_Y), radius, MX_Color, -1)\n",
    "        # 鼻翼下缘\n",
    "        NB = results.multi_face_landmarks[0].landmark[2]; NB_X, NB_Y = int(NB.x * w), int(NB.y * h); NB_Color = (180,187,28)\n",
    "        img = cv2.circle(img,(NB_X, NB_Y), radius, NB_Color, -1)\n",
    "        # 嘴唇中心\n",
    "        LC = results.multi_face_landmarks[0].landmark[13]; LC_X, LC_Y = int(LC.x * w), int(LC.y * h); LC_Color = (0,0,255)\n",
    "        img = cv2.circle(img,(LC_X, LC_Y), radius, LC_Color, -1)\n",
    "        # 嘴唇下缘\n",
    "        LB = results.multi_face_landmarks[0].landmark[17]; LB_X, LB_Y = int(LB.x * w), int(LB.y * h); LB_Color = (139,0,0)\n",
    "        img = cv2.circle(img,(LB_X, LB_Y), radius, LB_Color, -1)\n",
    "        # 从上到下六个点\n",
    "        Six_Y = np.array([FT_Y, MX_Y, NB_Y, LC_Y, LB_Y, FB_Y])\n",
    "        # 从最上到最下的距离\n",
    "        Top_Down = FB_Y - FT_Y\n",
    "        # 从上到下六个点间隔的五个距离，并归一化\n",
    "        Three_Section_Distance = 100 * np.diff(Six_Y) / Top_Down\n",
    "        # 三庭的后两庭是否接近，越小越好\n",
    "        Three_Section_Metric_A = np.abs(Three_Section_Distance[1] - sum(Three_Section_Distance[2:]))\n",
    "        # 鼻下到唇心距离 占 第三庭的三分之一\n",
    "        Three_Section_Metric_B = np.abs(Three_Section_Distance[2] - sum(Three_Section_Distance[2:])/3)\n",
    "        # 唇心到下巴尖距离 占 第三庭的二分之一\n",
    "        Three_Section_Metric_C = np.abs(sum(Three_Section_Distance[3:]) - sum(Three_Section_Distance[2:])/2)\n",
    "        \n",
    "        # 达芬奇\n",
    "        # 嘴唇左角\n",
    "        LL = results.multi_face_landmarks[0].landmark[61]; LL_X, LL_Y = int(LL.x * w), int(LL.y * h); LL_Color = (255,255,255)\n",
    "        img = cv2.circle(img,(LL_X, LL_Y), radius, LL_Color, -1)\n",
    "        # 嘴唇右角\n",
    "        LR = results.multi_face_landmarks[0].landmark[291]; LR_X, LR_Y = int(LR.x * w), int(LR.y * h); LR_Color = (255,255,255)\n",
    "        img = cv2.circle(img,(LR_X, LR_Y), radius, LR_Color, -1)\n",
    "        # 鼻子左缘\n",
    "        NL = results.multi_face_landmarks[0].landmark[129]; NL_X, NL_Y = int(NL.x * w), int(NL.y * h); NL_Color = (255,255,255)\n",
    "        img = cv2.circle(img,(NL_X, NL_Y), radius, NL_Color, -1)\n",
    "        # 鼻子右缘\n",
    "        NR = results.multi_face_landmarks[0].landmark[358]; NR_X, NR_Y = int(NR.x * w), int(NR.y * h); NR_Color = (255,255,255)\n",
    "        img = cv2.circle(img,(NR_X, NR_Y), radius, NR_Color, -1)\n",
    "        # 嘴宽为鼻宽的1.5-1.6倍\n",
    "        Da_Vinci = (LR.x - LL.x) / (NR.x - NL.x)\n",
    "        \n",
    "        # 眉毛\n",
    "        # 左眉毛左眉角：46\n",
    "        EBLL = results.multi_face_landmarks[0].landmark[46]; EBLL_X, EBLL_Y = int(EBLL.x * w), int(EBLL.y * h); EBLL_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(EBLL_X, EBLL_Y), radius, EBLL_Color, -1)\n",
    "        # 左眉毛眉峰：105\n",
    "        EBLT = results.multi_face_landmarks[0].landmark[105]; EBLT_X, EBLT_Y = int(EBLT.x * w), int(EBLT.y * h); EBLT_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(EBLT_X, EBLT_Y), radius, EBLT_Color, -1)\n",
    "        # 左眉毛右角：107\n",
    "        EBLR = results.multi_face_landmarks[0].landmark[107]; EBLR_X, EBLR_Y = int(EBLR.x * w), int(EBLR.y * h); EBLR_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(EBLR_X, EBLR_Y), radius, EBLR_Color, -1)\n",
    "        # 右眉毛左角：336\n",
    "        EBRL = results.multi_face_landmarks[0].landmark[336]; EBRL_X, EBRL_Y = int(EBRL.x * w), int(EBRL.y * h); EBRL_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(EBRL_X, EBRL_Y), radius, EBRL_Color, -1)\n",
    "        # 右眉毛眉峰：334\n",
    "        EBRT = results.multi_face_landmarks[0].landmark[334]; EBRT_X, EBRT_Y = int(EBRT.x * w), int(EBRT.y * h); EBRT_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(EBRT_X, EBRT_Y), radius, EBRT_Color, -1)\n",
    "        # 右眉毛右眉角：276\n",
    "        EBRR = results.multi_face_landmarks[0].landmark[276]; EBRR_X, EBRR_Y = int(EBRR.x * w), int(EBRR.y * h); EBRR_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(EBRR_X, EBRR_Y), radius, EBRR_Color, -1)\n",
    "        # 内测眉头在内眦（内测眼角）正上方-左侧\n",
    "        # 越接近0越好\n",
    "        EB_Metric_A = (EBLR_X - ELR_X) / Left_Right\n",
    "        # 内测眉头在内眦（内测眼角）正上方-右侧\n",
    "        # 越接近0越好\n",
    "        EB_Metric_B = (EBRL_X - ERL_X) / Left_Right\n",
    "        # 眉峰在外眦（外测眼角）正上方-左侧\n",
    "        # 越接近0越好\n",
    "        EB_Metric_C = (EBLT_X - ELL_X) / Left_Right\n",
    "        # 眉峰在外眦（外测眼角）正上方-右侧\n",
    "        # 越接近0越好\n",
    "        EB_Metric_D = (EBRT_X - ERR_X) / Left_Right\n",
    "        # 外侧眉峰、外侧眼角、鼻翼 应 处于同一条直线上-左侧\n",
    "        # 计算这三点构成的三角形面积，越小越好\n",
    "        EB_Metric_E = 0.5 * np.linalg.det([[EBLL_X,EBLL_Y,1],[ELL_X,ELL_Y,1],[NL_X,NL_Y,1]]) / (Left_Right)**2\n",
    "        # 外侧眉峰、外侧眼角、鼻翼 应 处于同一条直线上-右侧\n",
    "        # 计算这三点构成的三角形面积，越小越好\n",
    "        EB_Metric_F = 0.5 * np.linalg.det([[EBRR_X,EBRR_Y,1],[ERR_X,ERR_Y,1],[NR_X,NR_Y,1]]) / (Left_Right)**2\n",
    "        # 可视化\n",
    "        # 外侧眉峰、外侧眼角、鼻翼 应 处于同一条直线上-左侧\n",
    "        cv2.line(img,(EBLL_X, EBLL_Y),(ELL_X, ELL_Y), EBLL_Color, lw)\n",
    "        cv2.line(img,(ELL_X, ELL_Y),(NL_X, NL_Y), EBLL_Color, lw)\n",
    "        cv2.line(img,(EBLL_X, EBLL_Y),(NL_X, NL_Y), EBLL_Color, lw)\n",
    "        # 外侧眉峰、外侧眼角、鼻翼 应 处于同一条直线上-右侧\n",
    "        cv2.line(img,(EBRR_X, EBRR_Y),(ERR_X, ERR_Y), EBLL_Color, lw)\n",
    "        cv2.line(img,(ERR_X, ERR_Y),(NR_X, NR_Y), EBLL_Color, lw)\n",
    "        cv2.line(img,(EBRR_X, EBRR_Y),(NR_X, NR_Y), EBLL_Color, lw)\n",
    "        img = cv2.putText(img, 'Eyebrow', (25 * scaler, 500 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'A {:.2f} B {:.2f} C {:.2f} D {:.2f}'.format(EB_Metric_A,EB_Metric_B,EB_Metric_C,EB_Metric_D), (25 * scaler, 550 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'Eyebrow-Eye-Nose', (25 * scaler, 600 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'E {:.2f} F {:.2f}'.format(EB_Metric_E, EB_Metric_F), (25 * scaler, 650 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        \n",
    "        # 内眼角\n",
    "        # 左内眼角上点：157\n",
    "        ELRT = results.multi_face_landmarks[0].landmark[157]; ELRT_X, ELRT_Y = int(ELRT.x * w), int(ELRT.y * h); ELRT_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(ELRT_X, ELRT_Y), radius, ELRT_Color, -1)\n",
    "        # 左内眼角下点：154\n",
    "        ELRB = results.multi_face_landmarks[0].landmark[154]; ELRB_X, ELRB_Y = int(ELRB.x * w), int(ELRB.y * h); ELRB_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(ELRB_X, ELRB_Y), radius, ELRB_Color, -1)\n",
    "        # 右内眼角上点：384\n",
    "        ERLT = results.multi_face_landmarks[0].landmark[384]; ERLT_X, ERLT_Y = int(ERLT.x * w), int(ERLT.y * h); ERLT_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(ERLT_X, ERLT_Y), radius, ERLT_Color, -1)\n",
    "        # 右内眼角下点：381\n",
    "        ERRB = results.multi_face_landmarks[0].landmark[381]; ERRB_X, ERRB_Y = int(ERRB.x * w), int(ERRB.y * h); ERRB_Color = (0,255,255)\n",
    "        img = cv2.circle(img,(ERRB_X, ERRB_Y), radius, ERRB_Color, -1)\n",
    "        # 内眼角开合度数-左侧 \n",
    "        # 48度至50度为宜\n",
    "        vector_a = np.array([ELRT_X-ELR_X,ELRT_Y-ELR_Y])\n",
    "        vector_b = np.array([ELRB_X-ELR_X,ELRB_Y-ELR_Y])\n",
    "        cos = vector_a.dot(vector_b)/(np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "        EB_Metric_G = np.degrees(np.arccos(cos))\n",
    "        # 内眼角开合度数-右侧\n",
    "        # 48度至50度为宜\n",
    "        vector_a = np.array([ERLT_X-ERL_X,ERLT_Y-ERL_Y])\n",
    "        vector_b = np.array([ERRB_X-ERL_X,ERRB_Y-ERL_Y])\n",
    "        cos = vector_a.dot(vector_b)/(np.linalg.norm(vector_a) * np.linalg.norm(vector_b))\n",
    "        EB_Metric_H = np.degrees(np.arccos(cos))\n",
    "        # 可视化\n",
    "        cv2.line(img,(ELR_X, ELR_Y),(ELRT_X, ELRT_Y), ELRT_Color, lw) # 左侧内眦，眼角与内眼角上点连线\n",
    "        cv2.line(img,(ELR_X, ELR_Y),(ELRB_X, ELRB_Y), ELRB_Color, lw) # 左侧内眦，眼角与内眼角下点连线\n",
    "        cv2.line(img,(ERL_X, ELR_Y),(ERLT_X, ERLT_Y), ERLT_Color, lw) # 右侧内眦，眼角与内眼角上点连线\n",
    "        cv2.line(img,(ERL_X, ELR_Y),(ERRB_X, ERRB_Y), ERLT_Color, lw) # 右侧内眦，眼角与内眼角下点连线\n",
    "        img = cv2.putText(img, 'Inner Angle L:{:.2f} R:{:.2f}'.format(EB_Metric_G,EB_Metric_H), (25 * scaler, 700 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    \n",
    "        # 画五眼的竖线\n",
    "        cv2.line(img,(FL_X, FT_Y),(FL_X, FB_Y), FL_Color, lw)\n",
    "        cv2.line(img,(ELL_X, FT_Y),(ELL_X, FB_Y), ELL_Color, lw)\n",
    "        cv2.line(img,(ELR_X, FT_Y),(ELR_X, FB_Y), ELR_Color, lw)\n",
    "        cv2.line(img,(ERL_X, FT_Y),(ERL_X, FB_Y), ERL_Color, lw)\n",
    "        cv2.line(img,(ERR_X, FT_Y),(ERR_X, FB_Y), ERR_Color, lw)\n",
    "        cv2.line(img,(FR_X, FT_Y),(FR_X, FB_Y), FR_Color, lw)\n",
    "        # 画脸上下边缘的横线\n",
    "        cv2.line(img,(FL_X, FT_Y),(FR_X, FT_Y), FT_Color, lw)\n",
    "        cv2.line(img,(FL_X, FB_Y),(FR_X, FB_Y), FB_Color, lw)\n",
    "        # 画三庭的横线\n",
    "        cv2.line(img,(FL_X, MX_Y),(FR_X, MX_Y), MX_Color, lw)\n",
    "        cv2.line(img,(FL_X, NB_Y),(FR_X, NB_Y), NB_Color, lw)\n",
    "        cv2.line(img,(FL_X, LC_Y),(FR_X, LC_Y), LC_Color, lw)\n",
    "        cv2.line(img,(FL_X, LB_Y),(FR_X, LB_Y), LB_Color, lw)\n",
    "\n",
    "        scaler = 1\n",
    "        img = cv2.putText(img, 'Five Eye {:.2f}'.format(Five_Eye_Metrics), (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'A {:.2f}'.format(Five_Eye_Diff[0]), (25 * scaler, 150 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'B {:.2f}'.format(Five_Eye_Diff[2]), (25 * scaler, 200 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, 'C {:.2f}'.format(Five_Eye_Diff[4]), (25 * scaler, 250 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "\n",
    "        img = cv2.putText(img, 'Three Section {:.2f}'.format(Three_Section_Metric_A), (25 * scaler, 300 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, '1/3 {:.2f}'.format(Three_Section_Metric_B), (25 * scaler, 350 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "        img = cv2.putText(img, '1/2 {:.2f}'.format(Three_Section_Metric_C), (25 * scaler, 400 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "\n",
    "        img = cv2.putText(img, 'Da Vinci {:.2f}'.format(Da_Vinci), (25 * scaler, 450 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    else:\n",
    "        img = cv2.putText(img, 'No Face Detected', (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    \n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)\n",
    "    img = cv2.putText(img, 'FPS  '+str(int(FPS)), (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 调用摄像头获取每帧（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.691] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "# 调用摄像头逐帧实时处理模板\n",
    "# 不需修改任何代码，只需修改process_frame函数即可\n",
    "\n",
    "# 导入opencv-python\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 打开cap\n",
    "cap.open(0)\n",
    "\n",
    "# 无限循环，直到break被触发\n",
    "while cap.isOpened():\n",
    "    # 获取画面\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Error')\n",
    "        break\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ## !!!处理帧函数\n",
    "    frame = process_frame(frame)\n",
    "    \n",
    "    # 展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "\n",
    "    if cv2.waitKey(1) in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "        break\n",
    "    \n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果遇到Error，需检查其它notebook是否占用了摄像头，需在其它notebook中restart kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 视频逐帧处理（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频逐帧处理代码模板\n",
    "# 不需修改任何代码，只需定义process_frame函数即可\n",
    "\n",
    "def generate_video(input_path='./videos/three-hands.mp4'):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    \n",
    "    print('视频开始处理',input_path)\n",
    "    \n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为',frame_count)\n",
    "    \n",
    "    # cv2.namedWindow('Crack Detection and Measurement Video Processing')\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    \n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count-1) as pbar:\n",
    "        try:\n",
    "            while(cap.isOpened()):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                # 处理帧\n",
    "                # frame_path = './temp_frame.png'\n",
    "                # cv2.imwrite(frame_path, frame)\n",
    "                try:\n",
    "                    frame = process_frame(frame)\n",
    "                except:\n",
    "                    print('error')\n",
    "                    pass\n",
    "                \n",
    "                if success == True:\n",
    "                    # cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    # break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频开始处理 videos/single_person5_metrics.mp4\n",
      "视频总帧数为 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频已保存 out-single_person5_metrics.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_video(input_path='videos/single_person5_metrics.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dg_demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29ded39bd84ccde43438c3db4c0b346c1217eab52822133991d7d581c3429a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
