{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e23b8404",
   "metadata": {},
   "source": [
    "# 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19edd1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opencv-python\n",
    "import cv2\n",
    "# mediapipe人工智能工具包\n",
    "import mediapipe as mp\n",
    "# 进度条库\n",
    "from tqdm import tqdm\n",
    "# 时间库\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90059c71",
   "metadata": {},
   "source": [
    "# 导入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db4f180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入三维人脸关键点检测模型\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "model = mp_face_mesh.FaceMesh(   \n",
    "        static_image_mode=False,      # 是静态图片还是连续视频帧，摄像头画面为连续视频帧，此处选False\n",
    "        refine_landmarks=True,       # 使用Attention Mesh模型，对嘴唇、眼睛、瞳孔周围的关键点精细定位\n",
    "        max_num_faces=5,              # 最多检测几张脸\n",
    "        min_detection_confidence=0.5, # 置信度阈值\n",
    "        min_tracking_confidence=0.5,  # 追踪阈值\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5079ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# 导入可视化函数和可视化样式\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab5899f",
   "metadata": {},
   "source": [
    "# 处理单帧的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38aa2854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 处理帧函数\n",
    "def process_frame(img):\n",
    "    \n",
    "    # 记录该帧开始处理的时间\n",
    "    start_time = time.time()\n",
    "    scaler = 1 # 文字大小\n",
    "\n",
    "    # BGR转RGB\n",
    "    img_RGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    # 将RGB图像输入模型，获取预测结果\n",
    "    results = model.process(img_RGB)\n",
    "    \n",
    "    # 绘制人脸曲面和重点区域轮廓线\n",
    "    if results.multi_face_landmarks: # 如果检测出人脸\n",
    "        for face_landmarks in results.multi_face_landmarks: # 遍历每一张脸\n",
    "            # 绘制人脸网格\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=img,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "                # landmark_drawing_spec为关键点可视化样式，None为默认样式（不显示关键点）\n",
    "                # landmark_drawing_spec=mp_drawing.DrawingSpec(thickness=1, circle_radius=2, color=[66,77,229]),\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "            )\n",
    "\n",
    "            # 绘制脸轮廓、眼睫毛、眼眶、嘴唇\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=img,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "                # landmark_drawing_spec为关键点可视化样式，None为默认样式（不显示关键点）\n",
    "                # landmark_drawing_spec=mp_drawing.DrawingSpec(thickness=1, circle_radius=5, color=[66,77,229]),\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_contours_style()\n",
    "            )\n",
    "\n",
    "            # 绘制瞳孔区域\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image=img,\n",
    "                landmark_list=face_landmarks,\n",
    "                connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "                # landmark_drawing_spec为关键点可视化样式，None为默认样式（不显示关键点）\n",
    "                # landmark_drawing_spec=mp_drawing.DrawingSpec(thickness=1, circle_radius=1, color=[10,169,77]),\n",
    "                landmark_drawing_spec=None,\n",
    "                connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_iris_connections_style()\n",
    "            )\n",
    "    else:\n",
    "        img = cv2.putText(img, 'No Face Detected', (25 * scaler, 50 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "\n",
    "    # 记录该帧处理完毕的时间\n",
    "    end_time = time.time()\n",
    "    # 计算每秒处理图像帧数FPS\n",
    "    FPS = 1/(end_time - start_time)  \n",
    "\n",
    "    img = cv2.putText(img, 'FPS  '+str(int(FPS)), (25 * scaler, 100 * scaler), cv2.FONT_HERSHEY_SIMPLEX, 1.25 * scaler, (255, 0, 255), 2 * scaler)\n",
    "\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d022d583",
   "metadata": {},
   "source": [
    "# 调用摄像头获取每帧（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5df78396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@0.498] global /io/opencv/modules/videoio/src/cap_v4l.cpp (902) open VIDEOIO(V4L2:/dev/video1): can't open camera by index\n"
     ]
    }
   ],
   "source": [
    "# 调用摄像头逐帧实时处理模板\n",
    "# 不需修改任何代码，只需修改process_frame函数即可\n",
    "\n",
    "# 导入opencv-python\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# 获取摄像头，传入0表示获取系统默认摄像头\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "# 打开cap\n",
    "cap.open(0)\n",
    "\n",
    "# 无限循环，直到break被触发\n",
    "while cap.isOpened():\n",
    "    # 获取画面\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print('Error')\n",
    "        break\n",
    "    \n",
    "    ## !!!处理帧函数\n",
    "    frame = process_frame(frame)\n",
    "    \n",
    "    # 展示处理后的三通道图像\n",
    "    cv2.imshow('my_window',frame)\n",
    "\n",
    "    if cv2.waitKey(1) in [ord('q'),27]: # 按键盘上的q或esc退出（在英文输入法下）\n",
    "        break\n",
    "    \n",
    "# 关闭摄像头\n",
    "cap.release()\n",
    "\n",
    "# 关闭图像窗口\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0b279b",
   "metadata": {},
   "source": [
    "# 视频逐帧处理（模板）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b70f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 视频逐帧处理代码模板\n",
    "# 不需修改任何代码，只需定义process_frame函数即可\n",
    "\n",
    "def generate_video(input_path='./videos/three-hands.mp4'):\n",
    "    filehead = input_path.split('/')[-1]\n",
    "    output_path = \"out-\" + filehead\n",
    "    \n",
    "    print('视频开始处理',input_path)\n",
    "    \n",
    "    # 获取视频总帧数\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_count = 0\n",
    "    while(cap.isOpened()):\n",
    "        success, frame = cap.read()\n",
    "        frame_count += 1\n",
    "        if not success:\n",
    "            break\n",
    "    cap.release()\n",
    "    print('视频总帧数为',frame_count)\n",
    "    \n",
    "    # cv2.namedWindow('Crack Detection and Measurement Video Processing')\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    frame_size = (cap.get(cv2.CAP_PROP_FRAME_WIDTH), cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "    # fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (int(frame_size[0]), int(frame_size[1])))\n",
    "    \n",
    "    # 进度条绑定视频总帧数\n",
    "    with tqdm(total=frame_count-1) as pbar:\n",
    "        try:\n",
    "            while(cap.isOpened()):\n",
    "                success, frame = cap.read()\n",
    "                if not success:\n",
    "                    break\n",
    "\n",
    "                # 处理帧\n",
    "                # frame_path = './temp_frame.png'\n",
    "                # cv2.imwrite(frame_path, frame)\n",
    "                try:\n",
    "                    frame = process_frame(frame)\n",
    "                except:\n",
    "                    print('error')\n",
    "                    pass\n",
    "                \n",
    "                if success == True:\n",
    "                    # cv2.imshow('Video Processing', frame)\n",
    "                    out.write(frame)\n",
    "\n",
    "                    # 进度条更新一帧\n",
    "                    pbar.update(1)\n",
    "\n",
    "                # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    # break\n",
    "        except:\n",
    "            print('中途中断')\n",
    "            pass\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    out.release()\n",
    "    cap.release()\n",
    "    print('视频已保存', output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb22c50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频开始处理 videos/test_video.mp4\n",
      "视频总帧数为 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "视频已保存 out-test_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_video(input_path='videos/test_video.mp4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0129edcb",
   "metadata": {},
   "source": [
    "# 小作业：测试以下场景：\n",
    "\n",
    "张嘴、动眼睛、旋转脸部、戴口罩、手机照片、动画人物、绘画、密集人脸、小尺寸人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68876913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dg_demo')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f29ded39bd84ccde43438c3db4c0b346c1217eab52822133991d7d581c3429a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
